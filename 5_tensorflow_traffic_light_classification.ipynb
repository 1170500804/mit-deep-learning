{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#!/usr/bin/python2\n",
    "\n",
    "import sys, os, time\n",
    "import math, random\n",
    "import glob\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import cv2\n",
    "\n",
    "# Basic parameters\n",
    "\n",
    "max_epochs = 25\n",
    "base_image_path = \"5_tensorflow_traffic_light_images/\"\n",
    "image_types = [\"red\", \"green\", \"yellow\"]\n",
    "input_img_x = 32\n",
    "input_img_y = 32\n",
    "train_test_split_ratio = 0.9\n",
    "batch_size = 32\n",
    "checkpoint_name = \"model.ckpt\"\n",
    "\n",
    "# Helper layer functions\n",
    "def weight_variable(shape):\n",
    "    initial = tf.truncated_normal(shape, stddev=0.1)\n",
    "    return tf.Variable(initial)\n",
    "\n",
    "def bias_variable(shape):\n",
    "    initial = tf.constant(0.1, shape=shape)\n",
    "    return tf.Variable(initial)\n",
    "\n",
    "def conv2d(x, W, stride):\n",
    "    return tf.nn.conv2d(x, W, strides=[1, stride, stride, 1], padding='SAME')\n",
    "\n",
    "def max_pool_2x2(x):\n",
    "    return tf.nn.max_pool(x, ksize=[1, 2, 2, 1],\n",
    "                        strides=[1, 2, 2, 1], padding='SAME')\n",
    "\n",
    "# Model\n",
    "\n",
    "x = tf.placeholder(tf.float32, shape=[None, input_img_x, input_img_y, 3])\n",
    "y_ = tf.placeholder(tf.float32, shape=[None, len(image_types)])\n",
    "\n",
    "x_image = x\n",
    "\n",
    "# Our first three convolutional layers, of 16 3x3 filters\n",
    "W_conv1 = weight_variable([3, 3, 3, 16])\n",
    "b_conv1 = bias_variable([16])\n",
    "h_conv1 = tf.nn.relu(conv2d(x_image, W_conv1, 1) + b_conv1)\n",
    "\n",
    "W_conv2 = weight_variable([3, 3, 16, 16])\n",
    "b_conv2 = bias_variable([16])\n",
    "h_conv2 = tf.nn.relu(conv2d(h_conv1, W_conv2, 1) + b_conv2)\n",
    "\n",
    "W_conv3 = weight_variable([3, 3, 16, 16])\n",
    "b_conv3 = bias_variable([16])\n",
    "h_conv3 = tf.nn.relu(conv2d(h_conv2, W_conv3, 1) + b_conv3)\n",
    "\n",
    "# Our pooling layer\n",
    "\n",
    "h_pool4 = max_pool_2x2(h_conv3)\n",
    "\n",
    "n1, n2, n3, n4 = h_pool4.get_shape().as_list()\n",
    "\n",
    "W_fc1 = weight_variable([n2*n3*n4, 3])\n",
    "b_fc1 = bias_variable([3])\n",
    "\n",
    "# We flatten our pool layer into a fully connected layer\n",
    "\n",
    "h_pool4_flat = tf.reshape(h_pool4, [-1, n2*n3*n4])\n",
    "\n",
    "y = tf.matmul(h_pool4_flat, W_fc1) + b_fc1\n",
    "\n",
    "sess = tf.InteractiveSession()\n",
    "\n",
    "# Our loss function and optimizer\n",
    "\n",
    "loss = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(y, y_))\n",
    "train_step = tf.train.AdamOptimizer(1e-4).minimize(loss)\n",
    "sess.run(tf.initialize_all_variables())\n",
    "\n",
    "saver = tf.train.Saver()\n",
    "time_start = time.time()\n",
    "\n",
    "v_loss = least_loss = 99999999\n",
    "\n",
    "# Load data\n",
    "\n",
    "full_set = []\n",
    "\n",
    "for im_type in image_types:\n",
    "    for ex in glob.glob(os.path.join(base_image_path, im_type, \"*\")):\n",
    "        im = cv2.imread(ex)\n",
    "        if not im is None:\n",
    "            im = cv2.resize(im, (32, 32))\n",
    "\n",
    "            # Create an array representing our classes and set it\n",
    "            one_hot_array = [0] * len(image_types)\n",
    "            one_hot_array[image_types.index(im_type)] = 1\n",
    "            assert(im.shape == (32, 32, 3))\n",
    "\n",
    "            full_set.append((im, one_hot_array))\n",
    "\n",
    "random.shuffle(full_set)\n",
    "\n",
    "# We split our data into a training and test set here\n",
    "\n",
    "split_index = int(math.floor(len(full_set) * train_test_split_ratio))\n",
    "train_set = full_set[:split_index]\n",
    "test_set = full_set[split_index:]\n",
    "\n",
    "# We ensure that our training and test sets are a multiple of batch size\n",
    "train_set_offset = len(train_set) % batch_size\n",
    "test_set_offset = len(test_set) % batch_size\n",
    "train_set = train_set[: len(train_set) - train_set_offset]\n",
    "test_set = test_set[: len(test_set) - test_set_offset]\n",
    "\n",
    "train_x, train_y = zip(*train_set)\n",
    "test_x, test_y = zip(*test_set)\n",
    "\n",
    "print(\"Starting training... [{} training examples]\".format(len(train_x)))\n",
    "\n",
    "v_loss = 9999999\n",
    "\n",
    "for i in range(0, max_epochs):\n",
    "\n",
    "    # Iterate over our training set\n",
    "\n",
    "    for tt in range(0, (len(train_x) / batch_size)):\n",
    "        start_batch = batch_size * tt\n",
    "        end_batch = batch_size * (tt + 1)\n",
    "        train_step.run(feed_dict={x: train_x[start_batch:end_batch], y_: train_y[start_batch:end_batch]})\n",
    "        ex_seen = \"Current epoch, examples seen: {:20} / {} \\r\".format(tt * batch_size, len(train_x))\n",
    "        sys.stdout.write(ex_seen.format(tt * batch_size))\n",
    "        sys.stdout.flush()\n",
    "\n",
    "    ex_seen = \"Current epoch, examples seen: {:20} / {} \\r\".format((tt + 1) * batch_size, len(train_x))\n",
    "    sys.stdout.write(ex_seen.format(tt * batch_size))\n",
    "    sys.stdout.flush()\n",
    "\n",
    "    t_loss = loss.eval(feed_dict={x: train_x, y_: train_y})\n",
    "    v_loss = loss.eval(feed_dict={x: test_x, y_: test_y})\n",
    "\n",
    "    sys.stdout.write(\"Epoch {:5}: loss: {:15.10f}, val. loss: {:15.10f}\".format(i + 1, t_loss, v_loss))\n",
    "\n",
    "    if v_loss < least_loss:\n",
    "        sys.stdout.write(\", saving new best model to {}\".format(checkpoint_name))\n",
    "        least_loss = v_loss\n",
    "        filename = saver.save(sess, checkpoint_name)\n",
    "\n",
    "    sys.stdout.write(\"\\n\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
